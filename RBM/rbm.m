function [model, errors] = rbm(X, numhid, hidefunc, varargin)
% è¿™ä¸ªå‡½æ•°æ˜¯ç”¨æ¥å»ºç«‹ä¸€ä¸ªä¸¤å±‚çš„RBMï¼ŒVçš„ç»´åº¦æ˜¯Xçš„åˆ—æ•°ï¼ŒHçš„ç»´åº¦æ˜¯numhid
% vararginæ˜¯ç”¨æ¥è®¾ç½®RBMçš„å‚æ•°çš„ï¼Œé?å¸¸æŠŠverboseè®¾æˆtrueï¼Œå°±å¯ä»¥äº†ï¼Œå…¶ä»–é»˜è®¤å°±è¡Œï¼Œå½“ç„¶ä¹Ÿå¯ä»¥æ ¹æ®éœ?±‚æ¥æ”¹
%Learn RBM with Bernoulli hidden and visible units
%This is not meant to be applied to image data
%code by Andrej Karpathy
%based on implementation of Kevin Swersky and Ruslan Salakhutdinov

%INPUTS: 
%X              ... data. should be binary, or in [0,1] to be interpreted è®­ç»ƒæ•°æ®
%               ... as probabilities
%numhid         ... number of hidden layerséšå±‚èŠ‚ç‚¹æ•?
%additional inputs (specified as name value pairs or in struct)
%method         ... CD or SML 
%eta            ... learning rate åŠ¨é‡å­¦ä¹ ç?%momentum       ... momentum for smoothness amd to prevent overfitting åŠ¨é‡ï¼Œå¿«é€Ÿæ”¶æ•›é˜²æ­¢è¿‡æ‹Ÿåˆ
%               ... NOTE: momentum is not recommended with SML
%maxepoch       ... # of epochs: each is a full pass through train data æœ?¤§è®­ç»ƒæ¬¡æ•°
%avglast        ... how many epochs before maxepoch to start averaging
%               ... before. Procedure suggested for faster convergence by
%               åœ¨ä½¿ç”¨å¹³å‡åŒ–ä¹‹å‰è¦è¿è¡Œå¤šå°‘æ¬¡
%               ... Kevin Swersky in his MSc thesis
%penalty        ... weight decay factor æƒé‡è¡°å‡é¡?%batchsize      ... The number of training instances per batch è®­ç»ƒé›†ä¸­æ ·æœ¬çš„ä¸ªæ•?%verbose        ... For printing progress è¿™ä¸ªä¸œè¥¿å°±æ˜¯ä¸ºäº†æ‰“å°é‚£ä¸€è¡Œå­—
%anneal         ... Flag. If set true, the penalty is annealed linearly
%               ... through epochs to 10% of its original value

%OUTPUTS:
%model.type     ... Type of RBM (i.e. type of its visible and hidden units)
%model.W        ... The weights of the connections
%model.b        ... The biases of the hidden layer
%model.c        ... The biases of the visible layer
%model.top      ... The activity of the top layer, to be used when training
%               ... DBN's
%errors         ... The errors in reconstruction at every epoch

%Process options
%if args are just passed through in calls they become cells
if (isstruct(varargin)) 
    args= prepareArgs(varargin{1});
else
    args= prepareArgs(varargin);
end
[   method        ...
    eta           ...
    momentum      ...
    maxepoch      ...
    avglast       ...
    penalty       ...
    batchsize     ...
    verbose       ...
    anneal        ...
    ] = process_options(args    , ...
    'method'        ,  'CD'     , ...
    'eta'           ,  0.1      , ...
    'momentum'      ,  0.5      , ...
    'maxepoch'      ,  20       , ...
    'avglast'       ,  5        , ...
    'penalty'       , 2e-4      , ...
    'batchsize'     , 100       , ...
    'verbose'       , false     , ...
    'anneal'        , false);
avgstart = maxepoch - avglast;
oldpenalty= penalty;
[N,d]=size(X);

if (verbose) 
    fprintf('Preprocessing data...\n');
end

%Create batches
numcases=N;
numdims=d;
numbatches= ceil(N/batchsize);
groups= repmat(1:numbatches, 1, batchsize);
groups= groups(1:N);
perm=randperm(N);
groups = groups(perm);
for i=1:numbatches
    batchdata{i}= X(groups==i,:);
end

%train RBM 
W = 0.1*randn(numdims,numhid);
c = zeros(1,numdims);
b = zeros(1,numhid);
ph = zeros(numcases,numhid);
nh = zeros(numcases,numhid);
phstates = zeros(numcases,numhid);
nhstates = zeros(numcases,numhid);
negdata = zeros(numcases,numdims);
negdatastates = zeros(numcases,numdims);
Winc  = zeros(numdims,numhid); %æƒå?æ›´æ–°çš„å¤§å°?
binc = zeros(1,numhid); %éšå±‚åç§»æ›´æ–°çš„å¤§å°?
cinc = zeros(1,numdims); %æ˜¾å±‚åç§»æ›´æ–°çš„å¤§å°?
Wavg = W;
bavg = b;
cavg = c;
t = 1;
errors=zeros(1,maxepoch);

for epoch = 1:maxepoch
    
	errsum=0;
    if (anneal)
        %apply linear weight penalty decay
        penalty= oldpenalty - 0.9*epoch/maxepoch*oldpenalty;
    end
    
    for batch = 1:numbatches
		[numcases, numdims]=size(batchdata{batch});
		data = batchdata{batch};
        
        %go up ç¬¬ä¸€æ¬¡ä»æ˜¾å±‚åˆ°éšå±?		
        ph = hidefunc(data*W + repmat(b,numcases,1));
		phstates = ph > rand(numcases,numhid);
        if (isequal(method,'SML'))
            if (epoch == 1 && batch == 1)
                nhstates = phstates;
            end
        elseif (isequal(method,'CD'))
            nhstates = phstates;
        end
		
        %go down ç¬¬ä¸€æ¬¡ä»éšå±‚åˆ°æ˜¾å±?		
        negdata = hidefunc(nhstates*W' + repmat(c,numcases,1));
		negdatastates = negdata > rand(numcases,numdims);

        %go up one more timeç¬¬äºŒæ¬¡æ˜¾å±‚åˆ°éšå±‚
		nh = hidefunc(negdatastates*W + repmat(b,numcases,1));
		nhstates = nh > rand(numcases,numhid);
		
        %update weights and biases
        dW = (data'*ph - negdata'*nh);  %v1*h1-v2h2 Wçš„æ›´æ–°ï¼Œè¿™é‡Œæ˜¯ä¼¯åŠªåˆ©åˆ†å¸ƒçš„æ‰€ä»¥ç”¨çš„negdatastateï¼Œå¦‚æœä¸æ˜¯åˆ™å¯ä»¥æ”¹æˆnegdata
        dc = sum(data) - sum(negdata);  %v1 - v2æ˜¾å±‚åç§»çš„æ›´æ–?        
        db = sum(ph) - sum(nh); %h1-h2 éšå±‚åç§»çš„æ›´æ–?		
        Winc = momentum*Winc + eta*(dW/numcases - penalty*W); %Wçš„å¸¦åŠ¨é‡çš„æ›´æ–°çš„å¤§å°
		binc = momentum*binc + eta*(db/numcases);
		cinc = momentum*cinc + eta*(dc/numcases); 
		W = W + Winc; %Wçš„æ›´æ–?		b = b + binc;
		c = c + cinc;
        
        if (epoch > avgstart)
            %è¶…è¿‡45æ¬¡apply averaging
			Wavg = Wavg - (1/t)*(Wavg - W);%å…¶å®è¿™ä¸€æ­¥å°±æ˜¯æŠŠWçš„æ”¹å˜é‡ä»Wincå˜æˆäº?/t*Winc,ä¹Ÿå°±æ˜¯å‡å°äº†æ”¹å˜é‡?			
            cavg = cavg - (1/t)*(cavg - c);
			bavg = bavg - (1/t)*(bavg - b);
			t = t+1;
		else
			Wavg = W;
			bavg = b;
			cavg = c;
        end
        
        %accumulate reconstruction error
        err= sum(sum( (data-negdata).^2 )); %è¿™é‡Œä¸ºä»€ä¹ˆç”¨negdataè€Œä¸æ˜¯negdatastatesï¼?		errsum = err + errsum;
    end
    
    errors(epoch)=errsum;
    if (verbose) 
        fprintf('Ended epoch %i/%i. Reconstruction error is %f\n', ...
            epoch, maxepoch, errsum);
    end
end

model.top= hidefunc(X*Wavg + repmat(bavg,N,1));
model.W= Wavg;
model.b= bavg;
model.c= cavg;
